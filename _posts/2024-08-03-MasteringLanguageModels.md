---
title: "2024년 최신 언어 모델 정리"
description: ""
coverImage: "/assets/img/2024-08-03-MasteringLanguageModels_0.png"
date: 2024-08-03 21:28
ogImage: 
  url: /assets/img/2024-08-03-MasteringLanguageModels_0.png
tag: Tech
originalTitle: "Mastering Language Models"
link: "https://medium.com/towards-data-science/mastering-language-models-32e1d891511a"
isUpdated: true
updatedAt: 1723816517486
---



## 온도, 상위-p, 상위-k 등을 활용하여 품질-다양성 tradeoff를 탐색하기

만약 플레이그라운드나 API를 통해 언어 모델을 사용해본 적이 있다면, 입력 매개변수를 선택하라는 요청을 받았을 것입니다. 이러한 매개변수의 의미와 그들을 올바르게 사용하는 방법은 많은 사람들에게 명확하지 않을 수 있습니다.

![이미지](/assets/img/2024-08-03-MasteringLanguageModels_0.png)

본 글은 이러한 매개변수를 활용하여 환상을 제어하고 모델의 출력에 창의성을 불어넣으며, 다른 세밀한 조정을 통해 행위를 최적화하는 방법을 가르쳐줄 것입니다. 프롬프트 엔지니어링과 마찬가지로, 입력 매개변수 조정을 통해 모델을 110%로 운영할 수 있을 것입니다.

<div class="content-ad"></div>

이 기사를 끝내면 온도, 상위-p, 상위-k, 빈도 패널티 및 존재 패널티와 같은 다섯 가지 필수 입력 매개변수 전문가가 되실 겁니다. 또한 이러한 매개변수 각각이 품질-다양성 균형 유지에 어떻게 도움이 되는지 알게 될 겁니다.

그러니 커피를 가져오고, 시작해봅시다!

## 목차

- 배경
- 품질, 다양성, 및 온도
- 상위-k 및 상위-p
- 빈도 및 존재 패널티
- 매개변수 튜닝 치트 시트
- 마무리

<div class="content-ad"></div>

# 배경

입력 매개변수를 선택하기 전에 일부 백그라운드 정보를 살펴보아야 합니다. 이러한 모델이 어떻게 단어를 선택하는지에 대해 이야기해 봅시다.

문서를 읽기 위해 언어 모델은 토큰(sequence of tokens)으로 분해합니다. 토큰이란 모델이 쉽게 이해할 수 있는 작은 텍스트 조각입니다. 단어, 음절 또는 문자가 될 수 있습니다. 예를 들어, "Megaputer Intelligence Inc."이라는 문장은 다섯 개의 토큰으로 분해될 수 있습니다: ["Mega", "puter", "Intelligence", "Inc", "."].

대부분의 우리가 알고 있는 언어 모델은 시퀀스에서 다음 토큰을 반복적으로 생성합니다. 모델이 다음 토큰을 생성하려고 할 때마다 전체 시퀀스를 다시 읽고 그다음에 나올 토큰을 예측합니다. 이 전략을 자기회귀 생성이라고 합니다.

<div class="content-ad"></div>


![Image](https://miro.medium.com/v2/resize:fit:640/1*3S_Td7UNBT-u8pRnNiZ53w.gif)

ChatGPT가 단어들을 한 번에 하나씩 출력하는 이유를 설명하고 있습니다: 단어를 쓰는 대로 단어를 스트리밍해줍니다.

시퀀스에서 다음 토큰을 선택하기 위해 언어 모델은 먼저 어휘 사전에서 각 토큰에 대해 가능성 점수를 할당합니다. 모델이 평가하여 텍스트의 좋은 지속 또는 나쁜 지속인지를 나타내는 것이기 때문에, 토큰은 텍스트의 적합한 연속으로 간주되면 높은 가능성 점수를 얻고 그렇지 않으면 낮은 가능성 점수를 얻습니다.

![Image](/assets/img/2024-08-03-MasteringLanguageModels_1.png)


<div class="content-ad"></div>

확률 점수가 할당된 후, 토큰 샘플링 방법을 사용하여 토큰을 선택합니다. 이 때, 확률 점수가 고려됩니다. 토큰 샘플링 방법에는 어떤 무작위성을 포함할 수 있는데, 이는 언어 모델이 항상 똑같은 방식으로 같은 질문에 대답하지 않도록 합니다. 이러한 무작위성은 챗봇이나 다른 응용 프로그램에서 유용한 기능일 수 있습니다.

간단히 말하자면: 언어 모델은 텍스트를 토큰으로 분해하여 시퀀스에서 다음 토큰을 예측하고 일정 부분의 무작위성을 섞습니다. 필요할 때 반복하여 언어를 생성합니다.

# 품질, 다양성, 및 온도

하지만 왜 둘째로 최상의 토큰, 셋째로 최상의 토큰, 또는 최상의 토큰 이외의 다른 토큰을 선택하고 싶을까요? 사실상 최고의 토큰(가장 높은 확률 점수를 가진 토큰)을 매번 선택하고 싶지 않을까요? 종종, 그렇습니다. 그러나 매번 최상의 답을 선택한다면 매번 동일한 답을 얻게 되겠지요. 다양한 답변의 범위를 원한다면, 이를 위해 어느 정도의 품질을 포기해야 할 수도 있습니다. 이 품질 대 다양성 교환은 품질-다양성 트레이드오프라고 합니다.

<div class="content-ad"></div>

이를 고려하면 온도는 기계에게 품질 다양성 트레이드오프를 어떻게 탐색해야 하는지 알려줍니다. 낮은 온도는 더 많은 품질을, 높은 온도는 더 많은 다양성을 의미합니다. 온도가 0으로 설정되면 모델은 항상 가능성 점수가 가장 높은 토큰을 샘플링하므로 쿼리 사이에 다양성이 없지만, 모델이 평가한 가장 높은 품질의 연속성을 항상 선택하게 됩니다.

자주 온도를 0으로 설정하고 싶어할 것입니다. 원칙적으로 한 번만 모델에 제출할 예측에는 항상 온도 0을 선택해야 합니다. 이렇게 하는 것이 좋은 답변을 얻을 가능성이 가장 높습니다. 데이터 분석가로서 저는 엔티티 추출, 사실 추출, 감정 분석 및 대부분의 표준 작업에 대해 온도를 0으로 설정합니다.

높은 온도에서는 쓰레기와 환각이 더 많이 나타나며, 일관성이 줄어들고 평균적으로 답변의 품질이 낮아지지만, 창의성과 답변의 다양성이 더 높아집니다. 두 번 같은 질문을 하고 다른 답변을 얻고 싶을 때만 0이 아닌 온도를 사용하는 것이 좋습니다.

![그림](/assets/img/2024-08-03-MasteringLanguageModels_2.png)

<div class="content-ad"></div>

동일한 프롬프트에 대해 두 가지 다른 답변을 원하는 이유가 무엇인지요? 경우에 따라 한 프롬프트에 여러 가지 답변을 가지는 것이 유용할 수 있어요. 예를 들어, 한 프롬프트에 대해 여러 가지 답변을 생성하고 그 중 최상의 답변만 유지하는 기술이 있는데, 이는 종종 온도가 0인 단일 쿼리보다 더 나은 결과를 만들어 냅니다. 다른 사용 사례로는 합성 데이터 생성이 있어요. 우리는 매우 좋은 하나의 데이터 포인트뿐만 아니라 많은 서로 다른 합성 데이터 포인트를 원해요. 이러한 사용 사례(및 기타 사용 사례)를 나중에 논의할 수도 있지만, 대부분의 경우 우리는 프롬프트 당 한 가지 답변만을 원합니다. 의심스러울 때는 온도가 0인 것을 선택하세요!

이론적으로 온도가 0인 경우에는 매번 같은 답변이 나와야 하는 것이 중요합니다. 하지만 실제로는 그렇지 않을 수 있어요! 모델이 실행 중인 GPU가 반올림 오류와 같은 작은 연산 오차에 취약할 수 있기 때문에 이렇게 되는 경우도 있어요. 이러한 오류는 연산에 약간의 랜덤성을 도입하므로 온도가 0인 상태에서도 발생할 수 있어요. 텍스트에서 하나의 토큰을 변경하면 의미가 크게 변경될 수 있기 때문에, 단일 오류가 텍스트 내의 이후 토큰 선택에 거의 완전히 다른 결과를 초래할 수 있어요. 그러나 대체로 이러한 영향은 미미하다고 생각할 수 있어요. 온도가 0인 상황에서 약간의 랜덤성이 발생할 때 놀라지 않도록 언급하는 것 뿐이에요.

품질-다양성 트레이드오프를 조정하는 방법은 온도만 있는 것보다 훨씬 더 많아요. 다음 섹션에서는 온도 샘플링 기술에 대해 몇 가지 수정 사항을 논의할 거에요. 그러나 온도가 0인 상태를 사용하는 것에 만족하신다면, 일단 건너뛰셔도 괜찮아요. 온도가 0인 상태에서 이러한 매개 변수를 선택하는 것은 답변에 영향을 미치지 않을 것이라는 점을 확신하며 편히 쉬실 수 있어요.

TLDR(요약): 온도는 다양성을 증가시키지만, 난수를 모델 출력에 추가하여 품질을 낮춥니다.

<div class="content-ad"></div>

# Top-k 및 Top-p

우리의 토큰 샘플링 공식을 조정하는 일반적인 방법 중 하나는 Top-k 샘플링이라고 합니다. Top-k 샘플링은 일반적인 온도 샘플링과 매우 유사하지만, 확률이 낮은 토큰은 선택 대상에서 제외됩니다: “상위 k개”의 최상의 선택지만 고려됩니다. 이 방법의 장점은 실제로 잘못된 토큰을 선택하지 못하게 한다는 것입니다.

예를 들어, “태양은 ...에서 떠오릅니다”의 완성을 만들고 있다고 가정해 봅시다. 그렇지 않은 경우에는 모델이 단어장에서 가능한 모든 토큰을 시퀀스의 가능한 계속으로 고려합니다. 그런 다음 "태양은 냉장고에서 떠오름."과 같이 말도 안 되는 문장을 쓸 가능성이 있습니다. Top-k 샘플링을 사용하면 모델은 이러한 실제로 나쁜 선택지를 필터링하고 k개의 최상의 옵션만 고려합니다. 긴 꼬리를 잘라내면 다양성이 약간 감소하지만 우리의 품질은 훨씬 높아집니다.

![이미지](/assets/img/2024-08-03-MasteringLanguageModels_3.png)

<div class="content-ad"></div>

Top-k 샘플링은 당신이 원하는 다양성을 더 작은 품질 손실 비용으로 얻을 수 있는 방법입니다. 온도만 사용할 때보다 효과적입니다. 이 테크닉이 매우 효과적하기 때문에 다양한 변형을 갖추게 되었습니다.

Top-k 샘플링의 일반적인 변형 중 하나는 top-p 샘플링이며, nucleus 샘플링으로도 알려져 있습니다. Top-p 샘플링은 top-k와 매우 유사하지만, 꼬리를 어디에서 자를지 결정하는 데 토큰 순위 대신 가능성 점수를 사용합니다. 더 구체적으로 말하면, 결합된 가능성이 임계값 p를 초과하는 상위 순위 토큰만을 고려하며, 나머지는 버립니다.

많은 부적합한 또는 보통의 연속성이 있는 경우 top-p 샘플링의 힘은 뚜렷해집니다. 예를 들어 다음 토큰을 선택할 수 있는 좋은 후보가 소수이고, 개념적으로 약간 의미가 있는 것이 수십 개 있다고 가정해보겠습니다. k=25를 사용하여 top-k 샘플링을 하고 있다면, 많은 부적합한 연속성을 고려하게 될 것입니다. 반면에, 확률 분포의 하위 10%를 걸러내는 top-p 샘플링을 사용한다면, 좋은 토큰들만 고려하며 나머지를 걸러냅니다.

실제로, top-p 샘플링은 top-k 샘플링과 비교했을 때 결과가 더 나아집니다. 누적 가능성에 집중함으로써 입력의 맥락에 적응하고 더 유연한 차단점을 제공합니다. 결론적으로, top-p와 top-k 샘플링 모두 다양성을 포착하되 낮은 품질 비용으로 사용할 수 있지만, 일반적으로 top-p 샘플링이 더 나은 결과를 얻습니다.

<div class="content-ad"></div>

팁: 이 두 설정 모두, 낮은 값 = 더 많은 필터링을 의미합니다. 값이 0이면 상위 순위 토큰을 제외한 모든 것을 필터링하며, 이는 온도를 0으로 설정하는 효과와 동일합니다. 따라서 이러한 매개변수를 사용할 때 지나치게 낮게 설정하면 다양성이 전혀 없어지는 점을 유의해 주세요.

TL;DR: Top-k 및 top-p는 다양성에 큰 영향을 미치지 않고 품질을 향상시키는 데 작은 비용만 듭니다. 이러한 설정은 무작위 샘플링 전에 최악의 토큰 선택을 제거하여 이를 달성합니다.

# 빈도 및 존재 벌칙

우리가 논의할 파라미터는 이 두 가지 뿐이며, 일반적으로 우리가 마무리하려는 시점에 다가왔습니다: 빈도 및 존재 벌칙입니다. 이러한 매개변수는 품질과 다양성의 절충안을 탐색하는 또 다른 방법입니다. 그러나 온도 매개변수가 토큰 샘플링 절차에 무작위성을 추가하여 다양성을 달성하는 것과 달리, 빈도 및 존재 벌칙은 이미 텍스트에 나타난 토큰 재사용을 벌칙함으로써 다양성을 추가합니다. 이는 이전에 사용되거나 과도하게 사용된 토큰의 샘플링을 덜 가능하게 만들어 모델이 더 혁신적인 토큰 선택을 하도록 영향을 미칩니다.

<div class="content-ad"></div>

주파수 패널티는 텍스트에서 각 토큰이 발생한 횟수에 따라 토큰에 패널티를 추가합니다. 이는 동일한 토큰/단어/구문을 반복 사용하는 것을 억제하며, 모델이 더 다양한 주제를 논의하고 주제를 더 자주 변경하는 부작용도 가지고 있습니다. 반면, 존재 패널티는 텍스트에서 이미 발생한 토큰에 적용되는 고정 패널티이며, 모델이 더 많은 새로운 토큰/단어/구문을 도입하도록 유도하여 다양한 주제를 논의하고 주제를 더 자주 변경하게 합니다. 이로 인해 자주 사용되는 단어의 반복을 심하게 억제하진 않지만, 주제를 다양하게 논의하고 장르를 더 자주 변경하도록 유도합니다.

온도와 비슷하게, 주파수와 존재 패널티는 "최선"의 답변에서 더 창의적인 답변으로 이끕니다. 무작위성을 사용하는 대신, 정교하게 계산된 다양성을 주입하기 위해 대상 패널티를 추가합니다. 동일한 프롬프트에 대한 많은 답변이 필요한 드문 작업의 경우 (영구적이고 다양한 결과가 필요한 경우) 창의성을 증진시키기 위해 작은 주파수 또는 존재 패널티를 더하는 것도 고려해볼 수 있습니다. 그러나 한 번의 시도에서 하나의 정답을 찾고 싶은 프롬프트의 경우, 이러한 모든 매개변수를 '0'으로 설정하면 성공 확률이 가장 높습니다.

일반적으로 한 개의 올바른 답변이 있고 한 번만 질문하는 경우, 주파수 및 존재 패널티를 '0'으로 설정해야 합니다. 그러나 텍스트 요약과 같이 많은 올바른 답변이 있는 경우에는 조금의 재량이 있습니다. 모델의 출력이 지루하거나 창의성이 없거나 반복적이거나 범위가 제한된 것으로 보이면 주파수 또는 존재 패널티를 선별적으로 적용하여 활기를 불어넣는 좋은 방법이 될 수 있습니다. 그러나 이러한 매개변수에 대한 최종 제안도 온도에 대한 것과 같습니다: 어려울 때는 '0'을 선택하세요!

온도와 주파수/존재 패널티는 둘 다 모델의 응답에 다양성을 추가하지만, 추가되는 다양성의 종류는 서로 다릅니다. 주파수/존재 패널티는 단일 응답 내에서 다양성을 증가시킵니다. 즉, 답변에는 이러한 패널티 없이보다 다양한 단어, 구문, 주제 및 주제에 대한 내용이 포함됩니다. 그러나 동일한 프롬프트를 두 번 전달하면 두 개의 다른 답변을 얻을 확률이 더 높아지진 않습니다. 이것은 많은 번 모델에 동일한 프롬프트를 전달할 때 나타나는 온도와 대조적입니다. 높은 온도에서는 모델에 동일한 프롬프트를 여러 번 전달할 때 더 다양한 범위의 답변을 받을 것입니다.

<div class="content-ad"></div>

구분으로 '반응 내 다양성'과 '반응 간 다양성'이라는 용어를 사용하는 것을 좋아해요. 온도 매개변수는 '반응 내 다양성'과 '반응 간 다양성'을 동시에 추가하는 반면, 빈도/출현 페널티는 '반응 내 다양성'만 추가해요. 따라서, 우리가 다양성을 필요로 할 때, 매개변수 선택은 우리가 필요로 하는 종류의 다양성에 따라 달라져야 해요.

간단히 말하자면: 빈도와 출현 페널티는 모델이 다루는 주제의 다양성을 높이고 주제를 더 자주 변경하도록 만들어요. 빈도 페널티는 단어와 구문의 반복을 줄여주어 어휘 선택의 다양성을 높입니다.

# 매개변수 튜닝 치트 시트

이 섹션은 모델의 입력 매개변수 선택에 대한 실용적인 가이드로 의도되었어요. 먼저, 어떤 값을 제로로 설정해야 하는지에 대한 몇 가지 확고하고 빠른 규칙을 제공해요. 그런 다음, 0이 아닌 매개변수에 대한 올바른 값 찾는 데 도움이 되는 팁을 제시해줄 거예요.

<div class="content-ad"></div>

입력 매개변수를 선택할 때이 치트 시트를 사용하는 것을 적극 권장합니다. 지금이 페이지를 즐겨찾기에 추가해서 분실하지 않도록 하세요!

## 매개변수를 제로로 설정하는 규칙:

온도:

- 질문 당 하나의 답변의 경우: 0.
- 질문 당 여러 답변의 경우: 0이 아님.

<div class="content-ad"></div>

빈도와 존재 페널티:

- 하나의 올바른 답이 있는 경우: 제로.
- 여러 올바른 답이 있는 경우: 선택 사항.

최고 p/최고 k:

- 온도가 0일 때: 출력에 영향을 미치지 않음.
- 온도가 0이 아닐 때: 0이 아님.

<div class="content-ad"></div>

만약 여러분의 언어 모델에 여기 나열되지 않은 추가 매개변수가 있다면 그것들을 기본값으로 유지하는 것이 항상 괜찮습니다.

## 비제로 매개변수를 조정하는 팁:

0이 아닌 값을 가져야 하는 매개변수의 목록을 만든 다음, 실험을 해보기 위해 플레이그라운드로 가서 몇 가지 테스트 프롬프트를 실험해 보세요. 그러나 위의 규칙이 매개변수를 0으로 유지하도록 하는 경우, 0으로 유지하세요!

온도(top) / 최고 확률값(top-p) / 최고 문맥 길이(top-k) 조정하는 팁:

<div class="content-ad"></div>

- 다양성/랜덤성을 늘리려면 온도를 높여보세요.
- 온도를 조절하면서, 일정 값 이상은 보통 상위-p를 0.95(또는 상위-k를 250 정도)로 설정한 후 필요에 따라 줄여보세요.

문제 해결 방법:

- 너무 많은 허황, 쓰레기 또는 환각이 발생한다면, 온도를 낮추거나 상위-p/상위-k를 줄여보세요.
- 온도가 높으면서 다양성이 낮다면 상위-p/상위-k를 늘려보세요.

팁: 일부 인터페이스에서는 상위-p와 상위-k를 동시에 사용할 수 있지만, 한 가지만 선택하여 사용하시는 것이 좀 더 간단합니다. 상위-k는 사용과 이해하기 쉽지만, 상위-p가 더 효과적인 경우가 많습니다.

<div class="content-ad"></div>

튜닝 주파수 패널티와 존재 패널티:

- 더 다양한 주제와 내용을 원할 경우, 존재 패널티를 증가시킵니다.
- 더 다양하고 반복이 적은 언어를 원할 경우, 주파수 패널티를 증가시킵니다.

문제 해결:

- 출력물이 흩어지고 주제가 너무 빨리 변경된다면, 존재 패널티를 감소시킵니다.
- 너무 많은 새로운 고유어가 포함되어 있다거나, 존재 패널티를 0으로 설정하여도 여전히 주제 변경이 너무 많다면, 주파수 패널티를 감소시킵니다.

<div class="content-ad"></div>

TLDR: 언어 모델 튜닝을 위한 치트 시트로 사용할 수 있습니다. 이 규칙을 꼭 잊게 될 거니까 이 페이지를 즐겨찾기에 저장해두고 나중에 참고하세요.

# 마무리

토큰 샘플링 전략을 정의하는 무한한 방법이 있지만, 여기서 논의한 매개 변수인 온도, 상위-k, 상위-p, 빈도 벌점 및 존재 벌점은 Claude, Llama 및 GPT 시리즈와 같은 모델에서 찾을 수 있는 가장 일반적으로 사용되는 것들 중 하나입니다. 이러한 매개 변수는 모두 품질과 다양성의 균형을 유지하는 데 도움이 되는 것으로 보였습니다.

마지막으로 소개할 하나의 입력 매개 변수가 더 있습니다: 최대 토큰 길이입니다. 최대 토큰 길이는 모델이 답변을 출력하는 것을 멈추는 차단점일 뿐이며 완료되지 않았더라도 중단됩니다. 그 복잡한 토론 뒤에, 이 매개 변수는 쉽게 이해될 것이라고 기대합니다. 🙂

<div class="content-ad"></div>

시리즈가 진행될수록, 프롬프트 엔지니어링, 사용 사례에 적합한 언어 모델 선택 등에 대해 더 깊이 들어갈 것입니다! 또한 Megaputer Intelligence의 데이터 분석 컨설턴트로서 실제 업무에서 사용되는 몇 가지 사례들을 소개할 예정입니다. 더 많은 통찰을 기대해 주세요. 그리고 모델링 즐겁게 해보세요!

간략하게 말하자면: 의심스러울 때는 온도, 빈도 벌칙, 존재 벌칙을 모두 0으로 설정하세요. 그래도 작동하지 않는다면 위의 치트 시트를 참고하세요.